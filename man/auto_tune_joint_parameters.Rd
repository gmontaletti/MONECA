% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/joint_tuning.R
\name{auto_tune_joint_parameters}
\alias{auto_tune_joint_parameters}
\title{Joint Auto-Tuning for small.cell.reduction and cut.off Parameters}
\usage{
auto_tune_joint_parameters(
  mx,
  method = "grid",
  scr_range = c(0, NULL),
  cutoff_range = c(0.5, 3),
  scr_values = NULL,
  cutoff_values = NULL,
  n_grid_points = 10,
  n_bootstrap = 50,
  objectives = c("stability", "quality"),
  weights = NULL,
  seed = NULL,
  verbose = TRUE,
  parallel = "auto",
  plot_surface = FALSE,
  bayesian_iterations = 20,
  acquisition_function = "ei",
  exploration_factor = 0.1,
  n_initial = 5
)
}
\arguments{
\item{mx}{Mobility matrix to analyze. Must be a square numeric matrix.}

\item{method}{Character string specifying optimization strategy:
\itemize{
  \item "grid" (default): 2D grid search with stability assessment
  \item "bayesian": Bayesian optimization using Gaussian Process surrogate modeling
    with Expected Improvement or Upper Confidence Bound acquisition functions.
    Efficient for expensive evaluations, uses Latin Hypercube Sampling for
    initial design and sequential evaluation with adaptive point selection.
    Recommended when evaluation budget is limited or parameter space is large.
    \strong{Note: Sequential by mathematical necessity} - each new evaluation point
    depends on the GP model updated from all previous evaluations.
  \item "pareto": Multi-objective Pareto frontier optimization
  \item "adaptive": Adaptive refinement starting with coarse grid
}}

\item{scr_range}{Numeric vector of length 2 specifying the range for 
small.cell.reduction parameter. Default is c(0, NULL) where NULL 
auto-determines the upper bound. Ignored if scr_values is provided.}

\item{cutoff_range}{Numeric vector of length 2 specifying the range for 
cut.off parameter. Default is c(0.5, 3). Ignored if cutoff_values is provided.}

\item{scr_values}{Numeric vector of custom small.cell.reduction values to test.
If provided, overrides scr_range and n_grid_points for SCR dimension.
Values must be non-negative and will be converted to integers. Allows
for targeted testing of specific parameter values based on prior knowledge
or domain expertise. Default is NULL.}

\item{cutoff_values}{Numeric vector of custom cut.off values to test.
If provided, overrides cutoff_range and n_grid_points for cutoff dimension.
Values must be positive. Enables focused evaluation of specific threshold
values identified through previous analysis. Default is NULL.}

\item{n_grid_points}{Integer number of grid points per dimension for grid 
search. Default is 10. Ignored for dimensions with custom values.
Larger values provide finer resolution but increase computation time.}

\item{n_bootstrap}{Integer number of bootstrap samples for stability 
assessment. Default is 50. Higher values improve stability estimation
accuracy but increase computation time.}

\item{objectives}{Character vector of optimization objectives. Options include:
"stability", "quality", "sparsity", "modularity". 
Default is c("stability", "quality"). Multiple objectives are
combined using weighted aggregation.}

\item{weights}{Numeric vector of weights for combining multiple objectives.
Must sum to 1. Default is equal weights. Allows prioritization of
specific clustering properties in the optimization.}

\item{seed}{Integer seed for reproducibility. Default is NULL.
Ensures consistent results across runs when set.}

\item{verbose}{Logical indicating whether to show detailed progress information.
Default is TRUE. When enabled, displays real-time progress tracking with
ETA estimation, parameter evaluation updates, and performance statistics.
Progress tracking works seamlessly with both sequential and parallel execution.}

\item{parallel}{Character or logical indicating parallel processing preference.
Can be "auto" (default, intelligent switching), TRUE/FALSE (force parallel/sequential),
or "parallel"/"sequential" for explicit control. When "auto", the function
analyzes problem characteristics and system resources to make optimal decision.
Progress tracking is maintained across all parallel workers.
\strong{Method-specific behavior:}
\itemize{
  \item \strong{Grid search}: Can parallelize across parameter combinations
  \item \strong{Adaptive}: Can parallelize within each refinement phase  
  \item \strong{Bayesian}: Uses sequential evaluation regardless of this setting
    due to mathematical dependencies between evaluations. Individual evaluations
    may use internal parallelization if available.
}}

\item{plot_surface}{Logical indicating whether to plot optimization surface.
Default is FALSE. Creates interactive visualization of the parameter space
and optimization results when enabled.}

\item{bayesian_iterations}{Integer number of Bayesian optimization iterations.
Default is 20. Controls the number of sequential evaluations after initial
design points. Higher values allow more thorough exploration but increase
computation time. Only used when method = "bayesian".}

\item{acquisition_function}{Character string specifying acquisition function
for Bayesian optimization. Options are:
\itemize{
  \item "ei" (default): Expected Improvement - balances exploration and exploitation
  \item "ucb": Upper Confidence Bound - more exploration-focused
}
Only used when method = "bayesian".}

\item{exploration_factor}{Numeric exploration parameter for acquisition function.
Default is 0.1. Controls exploration vs exploitation trade-off:
\itemize{
  \item Smaller values (e.g., 0.01-0.05): More exploitation, faster convergence
  \item Larger values (e.g., 0.1-0.5): More exploration, better global search
}
Only used when method = "bayesian".}

\item{n_initial}{Integer number of initial design points for Bayesian optimization.
Default is 5. These points are sampled using Latin Hypercube Sampling to
provide good coverage of the parameter space before sequential optimization
begins. More points provide better initialization but increase initial cost.
Only used when method = "bayesian".}
}
\value{
A list of class "moneca_joint_tuning" containing:
  \item{optimal_scr}{Optimal small.cell.reduction value}
  \item{optimal_cutoff}{Optimal cut.off value}
  \item{optimization_surface}{Matrix of objective values for parameter grid}
  \item{parameter_grid}{Data frame of tested parameter combinations}
  \item{scores}{Detailed scores for each parameter combination}
  \item{method}{Optimization method used}
  \item{objectives}{Objectives optimized}
  \item{selection_rationale}{Explanation of parameter selection}
  \item{mathematical_relationship}{Estimated interaction effects}
  \item{computation_time}{Total optimization time}
  \item{scr_values}{Vector of tested small.cell.reduction values (custom or generated)}
  \item{cutoff_values}{Vector of tested cut.off values (custom or generated)}
  \item{performance_stats}{Optimization performance statistics including
                         parallel processing efficiency, cache utilization,
                         and progress tracking metrics}
}
\description{
Automatically selects optimal values for both small.cell.reduction and cut.off 
parameters simultaneously, considering their mathematical relationships and 
compound effects on clustering results. Features advanced progress tracking
and flexible parameter grid customization for efficient optimization.
}
\details{
This enhanced function provides comprehensive joint parameter optimization
with advanced features for progress tracking and custom parameter grids:

\strong{Mathematical Framework:}
The function considers the sequential filtering relationship between parameters:
1. small.cell.reduction filters raw counts: mx[mx < scr] = 0
2. Relative risk calculation: RR = Observed / Expected
3. cut.off filters relative risks: RR[RR < cutoff] = NA

Network density is affected multiplicatively by both parameters.
The function models this interaction to find optimal combinations.

\strong{Progress Tracking System:}
Real-time progress monitoring works seamlessly across execution modes:
\itemize{
  \item File-based progress tracking ensures visibility in parallel processing
  \item ETA estimation based on completed evaluations and current performance
  \item Progress updates shown at regular intervals (every 5% completion)
  \item Performance statistics including cache hit rates and evaluation speed
  \item Graceful degradation if progress tracking encounters issues
}

\strong{Custom Grid Vector Support:}
Flexible parameter specification allows targeted optimization:
\itemize{
  \item Custom vectors override ranges and grid point specifications
  \item Mixed usage: custom values for one parameter, range for another
  \item Automatic integer conversion for small.cell.reduction values
  \item Input validation ensures parameter feasibility
  \item Smart grid sizing based on problem characteristics
}

\strong{Performance Optimizations:}
Multiple efficiency enhancements improve user experience:
\itemize{
  \item Intelligent caching system reduces redundant computations
  \item Smart parameter ordering optimizes evaluation sequence
  \item Early termination for large parameter spaces when beneficial
  \item Adaptive parallel processing based on problem size and resources
  \item Memory management prevents cache overflow in long sessions
}

\strong{Bayesian Optimization Framework:}
The Bayesian method uses advanced machine learning techniques for efficient
parameter search, particularly beneficial for expensive evaluations:
\itemize{
  \item \strong{Gaussian Process surrogate modeling}: Builds a probabilistic model
    of the objective function that provides both predictions and uncertainty estimates
  \item \strong{Latin Hypercube Sampling}: Initial design points are strategically
    placed using space-filling design for optimal coverage
  \item \strong{Acquisition functions}: Balance exploration (searching uncertain regions)
    vs exploitation (searching near current best points):
    \itemize{
      \item Expected Improvement (EI): Maximizes expected improvement over current best
      \item Upper Confidence Bound (UCB): Optimizes upper confidence bound of predictions
    }
  \item \strong{Sequential evaluation}: Each new point is chosen to maximize
    information gain about the optimal parameter combination
  \item \strong{Adaptive point selection}: Later evaluations focus on most
    promising regions based on accumulated knowledge
}

\strong{Why Bayesian Optimization is Sequential:}
Bayesian optimization is inherently sequential due to its mathematical foundation:
\itemize{
  \item Each new evaluation point depends on the Gaussian Process model fitted to
    ALL previous evaluations
  \item The acquisition function requires the updated posterior distribution from
    all completed evaluations to select the next most informative point
  \item Parallel evaluation would select multiple points using the same outdated
    model, reducing the efficiency gained from adaptive point selection
  \item This sequential nature is what makes Bayesian optimization efficient:
    it typically finds good solutions with far fewer total evaluations than
    grid search, even though evaluations cannot be parallelized
}

\strong{Method Selection Guidelines:}
Choose optimization method based on problem characteristics:
\itemize{
  \item \strong{Grid search}: Best for small parameter spaces (≤100 evaluations),
    when comprehensive coverage is needed, or when evaluations are fast.
    Can fully utilize parallel processing for faster wall-clock time.
  \item \strong{Bayesian optimization}: Optimal for limited evaluation budgets,
    expensive function evaluations, large parameter spaces, or when seeking
    global optimum efficiently. Typically requires 15-50 evaluations.
    \strong{Sequential execution}: May appear slower per unit time due to lack
    of parallelization, but often faster overall due to requiring fewer total evaluations.
  \item \strong{Adaptive refinement}: Good compromise between thoroughness and
    efficiency, recommended for moderate-sized problems. Can parallelize within
    each refinement phase.
  \item \strong{Pareto optimization}: Use when multiple competing objectives
    need simultaneous consideration
}

\strong{Bayesian Optimization Tuning:}
Parameter selection for Bayesian optimization:
\itemize{
  \item \strong{n_initial}: More points (8-15) for complex landscapes, fewer (3-8)
    for smooth functions or limited budgets
  \item \strong{bayesian_iterations}: Typically 10-30 for most problems. More iterations
    allow better convergence but increase computational cost
  \item \strong{acquisition_function}: EI for balanced search, UCB for more exploration
  \item \strong{exploration_factor}: 0.01-0.05 for exploitation, 0.1-0.5 for exploration
}
}
\examples{
\dontrun{
# Generate sample data
mobility_data <- generate_mobility_data(n_classes = 6, seed = 123)

# Grid search optimization
joint_result <- auto_tune_joint_parameters(
  mx = mobility_data,
  method = "grid",
  n_grid_points = 15,
  verbose = TRUE,
  plot_surface = TRUE
)

# Use optimal parameters
segments <- moneca(
  mobility_data,
  small.cell.reduction = joint_result$optimal_scr,
  cut.off = joint_result$optimal_cutoff
)

# Adaptive refinement for efficiency
adaptive_result <- auto_tune_joint_parameters(
  mx = mobility_data,
  method = "adaptive",
  verbose = TRUE
)

# Custom parameter vectors for targeted testing
# Useful when you have domain knowledge about effective parameter ranges
custom_result <- auto_tune_joint_parameters(
  mx = mobility_data,
  method = "grid",
  scr_values = c(0, 1, 2, 5, 10),  # Specific SCR values to test
  cutoff_values = c(0.5, 1.0, 1.5, 2.0),  # Specific cutoff values
  verbose = TRUE  # Shows progress with ETA estimation
)

# Mixed usage - custom SCR values with cutoff range
# Demonstrates flexibility: custom vector + automatic range
mixed_result <- auto_tune_joint_parameters(
  mx = mobility_data,
  method = "grid",
  scr_values = c(0, 2, 5, 10, 15),  # Custom SCR values
  cutoff_range = c(0.8, 2.5),       # Automatic cutoff range
  n_grid_points = 8,                # Grid points for cutoff only
  verbose = TRUE
)

# Progress tracking demonstration
# Note: Progress output appears in console during execution
large_scale_result <- auto_tune_joint_parameters(
  mx = mobility_data,
  method = "grid",
  n_grid_points = 20,  # Creates 400 combinations
  parallel = "auto",   # Smart parallel processing
  verbose = TRUE       # Real-time progress with ETA
)

# Access enhanced return information
print(large_scale_result$performance_stats)  # Optimization efficiency
print(large_scale_result$scr_values)         # Actual values tested
print(large_scale_result$cutoff_values)      # Actual values tested

# Bayesian optimization for efficient parameter search
# Recommended when evaluation budget is limited or parameter space is large
bayesian_result <- auto_tune_joint_parameters(
  mx = mobility_data,
  method = "bayesian",
  bayesian_iterations = 15,  # Sequential evaluations after initial design
  acquisition_function = "ei", # Expected Improvement (balanced)
  exploration_factor = 0.1,   # Moderate exploration
  n_initial = 8,              # Initial Latin Hypercube points
  verbose = TRUE
)

# Bayesian optimization with high exploration for global search
# Useful for complex or multimodal parameter landscapes
exploratory_result <- auto_tune_joint_parameters(
  mx = mobility_data, 
  method = "bayesian",
  bayesian_iterations = 25,
  acquisition_function = "ucb", # Upper Confidence Bound (more exploratory)
  exploration_factor = 0.3,     # High exploration
  n_initial = 10,
  verbose = TRUE
)

# Efficient Bayesian search with custom parameter ranges
# Combines domain knowledge with efficient optimization
efficient_bayesian <- auto_tune_joint_parameters(
  mx = mobility_data,
  method = "bayesian",
  scr_range = c(0, 15),          # Custom SCR range based on data characteristics
  cutoff_range = c(0.8, 2.5),    # Custom cutoff range
  bayesian_iterations = 12,      # Fewer iterations for quick optimization
  acquisition_function = "ei",
  exploration_factor = 0.05,     # Low exploration for fast convergence
  n_initial = 5,                 # Minimal initial points
  verbose = TRUE
)

# Compare methods: Grid vs Bayesian efficiency
# Demonstrates when to use each approach

# For small parameter spaces: Grid search
grid_small <- auto_tune_joint_parameters(
  mx = mobility_data,
  method = "grid", 
  n_grid_points = 8,  # 64 total evaluations
  verbose = TRUE
)

# For equivalent evaluation budget: Bayesian optimization
bayesian_equivalent <- auto_tune_joint_parameters(
  mx = mobility_data,
  method = "bayesian",
  n_initial = 8,            # Initial design points  
  bayesian_iterations = 56, # Sequential evaluations (8 + 56 = 64 total)
  acquisition_function = "ei",
  exploration_factor = 0.1,
  verbose = TRUE
)

# Access Bayesian-specific results
print(bayesian_result$bayesian_info)      # Bayesian optimization details
print(bayesian_result$convergence_history) # Objective improvement over iterations
}

}
\seealso{
\code{\link{auto_tune_small_cell_reduction}},
\code{\link{analyze_parameter_interaction}},
\code{\link{plot_optimization_surface}},
\code{\link{clear_evaluation_caches}} for memory management,
\code{\link{detect_system_resources}} for parallel processing guidance
}
