---
title: "moneca Algorithm Comparison: moneca() vs moneca_fast()"
author: "Giampaolo Montaletti"
date: "`r Sys.Date()`"
output: 
  rmarkdown::html_vignette:
    toc: true
    toc_depth: 3
    fig_width: 8
    fig_height: 6
vignette: >
  %\VignetteIndexEntry{moneca Algorithm Comparison: moneca() vs moneca_fast()}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.path = "figures/",
  warning = FALSE,
  message = FALSE
)

# Check if required packages are available
required_packages <- c("ggplot2", "ggraph", "igraph", "dplyr", "tidygraph", "Matrix")
missing_packages <- required_packages[!sapply(required_packages, requireNamespace, quietly = TRUE)]

if (length(missing_packages) > 0) {
  knitr::opts_chunk$set(eval = FALSE)
  message("Some required packages are missing: ", paste(missing_packages, collapse = ", "))
  message("Code examples will not be evaluated.")
}
```

## Introduction

The moneca package provides two main algorithms for mobility network clustering analysis: the original `moneca()` function and the optimized `moneca_fast()` function. This vignette provides a detailed comparison of both algorithms, explaining their internal workflows, differences, and trade-offs to help users choose the most appropriate method for their analysis.

Both algorithms implement the same core MONECA methodology but with different optimization strategies and computational approaches. Understanding these differences is crucial for selecting the right tool based on your data size, computational resources, and accuracy requirements.

## Overview of the MONECA Methodology

Before diving into the specific implementations, it's important to understand the core MONECA methodology that both algorithms implement:

1. **Relative Risk Calculation**: Convert mobility tables to relative risk matrices
2. **Network Construction**: Create weighted networks from relative risk values
3. **Clique Detection**: Identify complete subgraphs (cliques) in the network
4. **Segmentation**: Group nodes into segments based on clique membership
5. **Aggregation**: Create new mobility tables aggregated by segments
6. **Iteration**: Repeat the process for multiple hierarchical levels

The key differences between `moneca()` and `moneca_fast()` lie in how they implement steps 3 (clique detection) and 4 (segmentation).

## The Original moneca() Algorithm

### Workflow Overview

The original `moneca()` function implements a conservative, thorough approach that prioritizes accuracy and reproducibility. Here's the detailed workflow:

```{r eval=FALSE}
# Load the package and create sample data with larger dimensions
library(moneca)
mobility_data <- generate_mobility_data(
  n_classes = 30, 
  n_total = 45000,
  class_names = paste("Class", sprintf("%02d", 1:30)),
  seed = 123
)

# Run the original algorithm
result_original <- moneca(mobility_data, segment.levels = 3)
```

### Step-by-Step Workflow

#### Step 1: Input Validation and Preprocessing
```{r eval=FALSE}
# The function begins with input validation for 30x30 matrix
mx <- mobility_data  # Input mobility table (30x30 + totals = 31x31)
segment.levels <- 3  # Number of hierarchical levels
cut.off <- 1         # Minimum relative risk threshold
cat("Processing matrix dimensions:", dim(mx), "\n")
cat("Total population:", mx[31, 31], "\n")
```

The algorithm expects a square mobility table with row and column totals in the last row and column.

#### Step 2: Relative Risk Matrix Calculation
```{r eval=FALSE}
# Internal function: weight.matrix() for 30x30 system
# Calculates observed/expected ratios for each cell
l <- nrow(mx)  # 31 for 30-class system
o.r.s <- mx[-l, l]        # Origin totals (30 values)
o.c.s <- mx[l, -l]        # Destination totals (30 values)
total.total <- mx[l,l]    # Grand total

cat("Weight matrix calculation:\n")
cat("Origin totals range:", min(o.r.s), "-", max(o.r.s), "\n")
cat("Destination totals range:", min(o.c.s), "-", max(o.c.s), "\n")
cat("Grand total:", total.total, "\n")

# Expected values under independence
row.share <- o.r.s/total.total
col.share <- o.c.s/total.total
total.mobility <- sum(mx[-l,-l])
mx.1_exp <- row.share %*% t(col.share) * total.mobility

# Relative risks (30x30 matrix)
mx.1_net <- mx[-l,-l] / mx.1_exp
mx.1i <- as.matrix(mx.1_net)
mx.1i[mx.1i < cut.off] <- NA  # Apply threshold
mx.1i <- mx.1i + t(mx.1i)     # Make symmetric
diag(mx.1i) <- NA             # Remove diagonal

cat("Significant edges (RR > 1):", sum(!is.na(mx.1i)), "out of", 30*29, "possible\n")
```

#### Step 3: Network Construction
```{r eval=FALSE}
# Convert to adjacency matrix for graph creation
mx.1i.graph <- mx.1i
mx.1i.graph[is.na(mx.1i.graph)] <- 0

# Create undirected, weighted graph
gra.1ii <- moneca_graph_from_adjacency(
  adjmatrix = mx.1i.graph, 
  mode = "undirected", 
  weighted = TRUE, 
  diag = FALSE
)
```

#### Step 4: Clique Detection
```{r eval=FALSE}
# Find ALL cliques in the 30-node network
clique <- moneca_cliques(gra.1ii)
cat("Total cliques found:", length(clique), "\n")
if(length(clique) > 0) {
  clique_sizes <- sapply(clique, length)
  cat("Clique size distribution:\n")
  cat("  Min size:", min(clique_sizes), "\n")
  cat("  Max size:", max(clique_sizes), "\n")
  cat("  Mean size:", round(mean(clique_sizes), 1), "\n")
  cat("  Size frequency:", paste(names(table(clique_sizes)), "nodes:", table(clique_sizes), "cliques", collapse = "; "), "\n")
}
```

**Key characteristic**: The original algorithm finds ALL cliques in the network, including overlapping ones. This provides comprehensive coverage but can be computationally expensive for dense networks.

#### Step 5: Edge Processing and Segmentation
```{r eval=FALSE}
# The find.segments() function processes edges in order of strength
# Extract edges and sort by weight (strongest first)
edges <- which(!is.na(mat) & mat > cut.off, arr.ind = TRUE)
edge_weights <- mat[edges]
edge_order <- order(edge_weights, decreasing = TRUE)
edges <- edges[edge_order, , drop = FALSE]

# Initialize group assignments
group <- vector(mode = "numeric", length = nrow(mat))
names(group) <- rownames(mat)

# Process each edge in order of decreasing strength
for (i in seq_len(nrow(edges))) {
  edge <- edges[i, ]
  current_groups <- group[edge]
  
  # Determine group assignment based on existing memberships
  # and clique constraints
  if (sum(current_groups) == 0) {
    # Both nodes unassigned: create new group
    group[edge] <- i  
  } else {
    # At least one node assigned: test clique membership
    group.candidates <- current_groups[current_groups != 0] 
    group.members <- which(group %in% group.candidates)
    potential.clique <- unique(sort(c(group.members, edge)))
    
    # Test if potential group forms a valid clique
    test <- clique.test(cliques, potential.clique)
    if (test == TRUE) {
      group[potential.clique] <- group.assigned             
    }
  }
}
```

**Key characteristics**:
- **Sequential processing**: Edges are processed one by one in order of strength
- **Clique validation**: Every potential group is tested against all known cliques
- **Conservative grouping**: Groups are only formed if they satisfy clique constraints

#### Step 6: Matrix Aggregation
```{r eval=FALSE}
# Aggregate the original mobility table by the identified segments
groups.1 <- c(segments$membership, length(segments$membership) + 1)
mx.2_r <- rowsum(mx, groups.1)
mx.2_r_t <- t(mx.2_r)
mx.2_rc_t <- rowsum(mx.2_r_t, groups.1)
mx.2g <- t(mx.2_rc_t)
```

#### Step 7: Hierarchical Iteration
```{r eval=FALSE}
# Repeat the process for the aggregated matrix
# Continue until segment.levels is reached or no further segmentation possible
for (i in 2:segment.levels) {
  segments <- make.segments(mx.2g, cut.off, mode, delete.upper.tri, small.cell.reduction)
  mx.2g <- segment.matrix(mx.2g, segments)
  # ... store results for level i
}
```

### Advantages of moneca()

1. **Accuracy**: Finds all cliques, ensuring no potential segments are missed
2. **Deterministic**: Results are completely reproducible
3. **Thorough**: Conservative approach minimizes false segmentation
4. **Well-tested**: Extensively validated algorithm with proven track record
5. **Comprehensive**: Handles edge cases and complex network structures reliably

### Disadvantages of moneca()

1. **Computational complexity**: O(3^n) in worst case for clique enumeration
2. **Memory intensive**: Stores all cliques in memory
3. **Slow for large networks**: Performance degrades significantly with network size
4. **No early stopping**: Processes all edges even when further segmentation is unlikely

## The Optimized moneca_fast() Algorithm

### Workflow Overview

The `moneca_fast()` function implements several optimization strategies while maintaining the core MONECA methodology. It prioritizes computational efficiency while preserving algorithmic accuracy for most practical use cases.

```{r eval=FALSE}
# Run the optimized algorithm on 30x30 data
result_fast <- moneca_fast(
  mobility_data, 
  segment.levels = 3,
  use.sparse = FALSE,        # Optional sparse matrix support
  min.density = 0.01,        # Early stopping threshold
  max.clique.size = 8,       # Limit clique size for 30-node network
  progress = TRUE            # Progress monitoring
)

cat("Fast algorithm completed for 30x30 matrix\n")
cat("Levels processed:", length(result_fast$segment.list), "\n")
```

### Step-by-Step Workflow

#### Step 1: Enhanced Input Validation and Configuration
```{r eval=FALSE}
# Additional parameters for optimization (tuned for 30x30 system)
use.sparse <- FALSE           # Sparse matrix support
min.density <- 0.01          # Minimum edge density for continuation
max.clique.size <- 10        # Limit for computational efficiency with 30 nodes
progress <- TRUE             # Progress bar display

cat("Optimization parameters for 30-class system:\n")
cat("  Sparse matrices:", use.sparse, "\n")
cat("  Min density threshold:", min.density, "\n")
cat("  Max clique size limit:", max.clique.size, "\n")
```

#### Step 2: Optimized Relative Risk Calculation
```{r eval=FALSE}
# Fast weight matrix calculation with vectorized operations
weight.matrix.fast <- function(mx, cut.off = 1, symmetric = TRUE, 
                               diagonal = NULL, small.cell.reduction = 0) {
  l <- nrow(mx)
  
  # Vectorized operations for better performance
  o.r.s <- mx[-l, l]
  o.c.s <- mx[l, -l]
  total.total <- mx[l, l]
  row.share <- o.r.s / total.total
  col.share <- o.c.s / total.total
  total.mobility <- sum(mx[-l, -l])
  
  # Vectorized expected calculation using outer product
  mx.1_exp <- outer(row.share, col.share) * total.mobility
  
  # Continue with relative risk calculation...
}
```

**Optimization**: Uses vectorized operations and `outer()` for more efficient matrix calculations.

#### Step 3: Sparse Matrix Support (Optional)
```{r eval=FALSE}
# Convert to sparse matrix if requested and beneficial
if (use.sparse && requireNamespace("Matrix", quietly = TRUE)) {
  if (!inherits(mx, "sparseMatrix")) {
    mx <- Matrix::Matrix(mx, sparse = TRUE)
  }
}
```

**Optimization**: Optional sparse matrix support for large, sparse datasets.

#### Step 4: Maximal Clique Detection
```{r eval=FALSE}
# Use MAXIMAL cliques instead of ALL cliques (critical for 30-node networks)
if (is.null(max.clique.size)) {
  cliques <- moneca_max_cliques(graph, min = 2)
  cat("Finding all maximal cliques\n")
} else {
  cliques <- moneca_max_cliques(graph, min = 2, max = max.clique.size)
  cat("Finding maximal cliques with size limit:", max.clique.size, "\n")
}

cat("Maximal cliques found:", length(cliques), "\n")
if(length(cliques) > 0) {
  max_clique_sizes <- sapply(cliques, length)
  cat("Maximal clique sizes - Min:", min(max_clique_sizes), 
      "Max:", max(max_clique_sizes), 
      "Mean:", round(mean(max_clique_sizes), 1), "\n")
}
```

**Key optimization**: Uses maximal cliques instead of all cliques. Maximal cliques are cliques that cannot be extended by adding another vertex, which significantly reduces the number of cliques to consider while maintaining algorithmic soundness.

#### Step 5: Early Stopping Based on Density
```{r eval=FALSE}
# Early stopping if graph becomes too sparse
density <- igraph::edge_density(graph)
if (density < min.density) {
  n <- nrow(mat)
  out <- list(
    membership = as.factor(1:n),
    cliques = as.list(1:n)
  )
  return(out)  # Return trivial segmentation
}
```

**Optimization**: Stops processing when network density falls below threshold, indicating limited potential for meaningful segmentation.

#### Step 6: Vectorized Edge Processing
```{r eval=FALSE}
# Vectorized edge extraction and sorting
edges <- which(!is.na(mat) & mat > cut.off, arr.ind = TRUE)
edge_weights <- mat[edges]
edge_order <- order(edge_weights, decreasing = TRUE)
edges <- edges[edge_order, , drop = FALSE]

# Pre-compute clique membership matrix for fast testing
clique_membership <- matrix(FALSE, nrow = length(cliques), ncol = nrow(mat))
for (i in seq_along(cliques)) {
  clique_membership[i, cliques[[i]]] <- TRUE
}
```

**Optimization**: Pre-computes clique membership matrix for O(1) clique testing instead of repeated searches.

#### Step 7: Optimized Segmentation Algorithm
```{r eval=FALSE}
# Fast clique test using pre-computed membership
is_clique <- any(apply(clique_membership[, potential_clique, drop = FALSE], 1, all))

if (is_clique) {
  # Merge groups - use the smallest group number
  target_group <- min(assigned_groups)
  group[potential_clique] <- target_group
}
```

**Optimization**: Uses matrix operations for clique testing instead of iterative searches.

#### Step 8: Optimized Level Processing
```{r eval=FALSE}
# Optimized level.down function with vectorized operations
level.down.fast <- function(level.current, level.below) {
  # Remove isolates efficiently
  lengths <- lengths(level.current)
  level.current <- level.current[lengths > 1]
  
  if (length(level.current) == 0) return(list())
  
  # Vectorized operation using lapply
  ud <- lapply(level.current, function(d) unlist(level.below[d]))
  return(ud)
}
```

**Optimization**: Uses vectorized operations and `lengths()` for more efficient processing.

### Advantages of moneca_fast()

1. **Performance**: Significantly faster, especially for larger networks
2. **Memory efficient**: Uses maximal cliques to reduce memory footprint
3. **Early stopping**: Avoids unnecessary computation when segmentation potential is low
4. **Sparse matrix support**: Handles large sparse matrices efficiently
5. **Progress monitoring**: Provides feedback for long-running analyses
6. **Scalable**: Better performance scaling with network size

### Disadvantages of moneca_fast()

1. **Potentially less comprehensive**: Maximal cliques might miss some valid segments
2. **Early stopping trade-offs**: May terminate segmentation prematurely in some cases
3. **Complexity**: More parameters to tune (density thresholds, clique size limits)
4. **Less tested**: Newer algorithm with less extensive validation
5. **Parameter sensitivity**: Results may be more sensitive to parameter choices

## Detailed Algorithm Comparison

### Clique Detection Strategies

**moneca()**: Uses ALL cliques
```{r eval=FALSE}
# Finds every possible clique in the network
cliques <- moneca_cliques(graph)
# For a 6-node complete graph: finds 2^6 - 6 - 1 = 57 cliques
```

**moneca_fast()**: Uses MAXIMAL cliques
```{r eval=FALSE}
# Finds only maximal cliques (cannot be extended)
cliques <- moneca_max_cliques(graph, min = 2)
# For a 6-node complete graph: finds only 1 maximal clique
```

### Computational Complexity

| Aspect | moneca() | moneca_fast() |
|--------|----------|---------------|
| Clique enumeration | O(3^n) worst case | O(d^3) where d is degeneracy |
| Memory usage | O(2^n) for storing cliques | O(k) where k is number of maximal cliques |
| Edge processing | O(m × c) where c is clique count | O(m × log(c)) with pre-computed lookup |
| Overall complexity | Exponential in worst case | Polynomial in most practical cases |

### Performance Characteristics

```{r eval=FALSE}
# Benchmarking example (not run in vignette)
library(microbenchmark)

# Small network (6 nodes)
small_data <- generate_mobility_data(n_classes = 6, seed = 123)
microbenchmark(
  original = moneca(small_data, segment.levels = 2),
  fast = moneca_fast(small_data, segment.levels = 2, progress = FALSE),
  times = 10
)

# Medium network (12 nodes)
medium_data <- generate_mobility_data(n_classes = 12, seed = 123)
microbenchmark(
  original = moneca(medium_data, segment.levels = 2),
  fast = moneca_fast(medium_data, segment.levels = 2, progress = FALSE),
  times = 5
)
```

Expected performance differences:
- **Small networks (< 10 nodes)**: Minimal difference, sometimes original is faster due to lower overhead
- **Medium networks (10-20 nodes)**: Fast version typically 2-5x faster
- **Large networks (> 20 nodes)**: Fast version can be 10-100x faster or more

## Practical Examples

### Example 1: Small Dataset Comparison

```{r small-example}
library(moneca)

# Generate a medium-sized mobility dataset (30 classes) for meaningful comparison
medium_data <- generate_mobility_data(
  n_classes = 30, 
  n_total = 40000,
  immobility_strength = 0.8, 
  class_names = paste("Class", sprintf("%02d", 1:30)),
  seed = 42
)

cat("Generated 30x30 mobility matrix\n")
cat("Dimensions:", dim(medium_data), "\n")
cat("Total population:", medium_data[31, 31], "\n")
cat("Overall mobility rate:", 
    round((1 - sum(diag(medium_data[1:30, 1:30])) / sum(medium_data[1:30, 1:30])) * 100, 1), "%\n\n")

# Show representative portion of the matrix
cat("First 6x6 corner with totals:\n")
print(medium_data[c(1:6, 31), c(1:6, 31)])

# Run both algorithms
result_original <- moneca(medium_data, segment.levels = 2)
result_fast <- moneca_fast(medium_data, segment.levels = 2, max.clique.size = 8, progress = FALSE)

# Compare results
cat("\nOriginal algorithm - Level 2 segmentation:\n")
original_segments <- result_original$segment.list[[2]]
cat("Number of segments:", length(original_segments), "\n")
segment_sizes_orig <- sapply(original_segments, length)
cat("Segment sizes:", paste(sort(segment_sizes_orig, decreasing = TRUE), collapse = ", "), "\n")

cat("\nFast algorithm - Level 2 segmentation:\n")
fast_segments <- result_fast$segment.list[[2]]
cat("Number of segments:", length(fast_segments), "\n")
segment_sizes_fast <- sapply(fast_segments, length)
cat("Segment sizes:", paste(sort(segment_sizes_fast, decreasing = TRUE), collapse = ", "), "\n")

# Check if results are identical
identical_results <- identical(result_original$segment.list, result_fast$segment.list)
cat("\nResults identical:", identical_results, "\n")

# If not identical, show differences
if(!identical_results) {
  cat("\nAlgorithm comparison summary:\n")
  cat("Original - Segments:", length(original_segments), ", Avg size:", round(mean(segment_sizes_orig), 1), "\n")
  cat("Fast - Segments:", length(fast_segments), ", Avg size:", round(mean(segment_sizes_fast), 1), "\n")
}
```

### Example 2: Performance Comparison

```{r performance-example}
# Generate large dataset for meaningful performance comparison (30 classes)
large_data <- generate_mobility_data(
  n_classes = 30, 
  n_total = 50000,
  class_names = paste("Class", sprintf("%02d", 1:30)),
  seed = 123
)

cat("Performance test with 30x30 mobility matrix\n")
cat("Matrix dimensions:", dim(large_data), "\n")
cat("Population:", large_data[31, 31], "\n\n")

# Time both algorithms
cat("Timing original algorithm...\n")
time_original <- system.time({
  result_orig <- moneca(large_data, segment.levels = 2, small.cell.reduction = 15)
})

cat("Timing fast algorithm...\n")
time_fast <- system.time({
  result_fast <- moneca_fast(
    large_data, 
    segment.levels = 2, 
    max.clique.size = 8,
    progress = FALSE
  )
})

cat("\nPerformance Results:\n")
cat("Original algorithm time:", round(time_original["elapsed"], 2), "seconds\n")
cat("Fast algorithm time:", round(time_fast["elapsed"], 2), "seconds\n")
if(time_fast["elapsed"] > 0) {
  speedup <- time_original["elapsed"] / time_fast["elapsed"]
  cat("Speedup factor:", round(speedup, 2), "x\n")
} else {
  cat("Fast algorithm completed in < 0.01 seconds\n")
}

# Compare segmentation quality
cat("\nSegmentation quality comparison:\n")
cat("Original - Segments:", length(result_orig$segment.list[[2]]), "\n")
cat("Fast - Segments:", length(result_fast$segment.list[[2]]), "\n")

# Check memory usage approximation
cat("\nApproximate object sizes:\n")
cat("Original result:", round(object.size(result_orig) / 1024^2, 2), "MB\n")
cat("Fast result:", round(object.size(result_fast) / 1024^2, 2), "MB\n")
```

### Example 3: Different Segmentation Outcomes

Sometimes the algorithms may produce different results due to their different clique detection strategies:

```{r different-outcomes}
# Create a complex 30-class dataset where algorithms might differ
complex_data <- generate_mobility_data(
  n_classes = 30, 
  n_total = 35000,
  immobility_strength = 0.6,  # Lower immobility for more complex structure
  class_clustering = 0.3,     # Some clustering
  noise_level = 0.1,         # Some noise
  class_names = paste("Class", sprintf("%02d", 1:30)),
  seed = 789
)

cat("Complex 30-class mobility system:\n")
cat("Dimensions:", dim(complex_data), "\n")
cat("Population:", complex_data[31, 31], "\n")
cat("Mobility rate:", 
    round((1 - sum(diag(complex_data[1:30, 1:30])) / sum(complex_data[1:30, 1:30])) * 100, 1), "%\n\n")

# Run both algorithms
seg_original <- moneca(complex_data, segment.levels = 3, small.cell.reduction = 10)
seg_fast <- moneca_fast(complex_data, segment.levels = 3, max.clique.size = 6, progress = FALSE)

# Compare segment structures
cat("Algorithm comparison for Level 2 segmentation:\n")
original_level2 <- seg_original$segment.list[[2]]
fast_level2 <- seg_fast$segment.list[[2]]

cat("Original algorithm - ", length(original_level2), "segments:\n")
for(i in 1:length(original_level2)) {
  segment_classes <- original_level2[[i]]
  cat("  Segment", i, "(", length(segment_classes), "classes): ", 
      paste(segment_classes[1:min(5, length(segment_classes))], collapse = ", "),
      if(length(segment_classes) > 5) "..." else "", "\n")
}

cat("\nFast algorithm - ", length(fast_level2), "segments:\n")
for(i in 1:length(fast_level2)) {
  segment_classes <- fast_level2[[i]]
  cat("  Segment", i, "(", length(segment_classes), "classes): ", 
      paste(segment_classes[1:min(5, length(segment_classes))], collapse = ", "),
      if(length(segment_classes) > 5) "..." else "", "\n")
}

# Compare number of segments at each level
levels_orig <- sapply(seg_original$segment.list, length)
levels_fast <- sapply(seg_fast$segment.list, length)

# Ensure both have same length by padding with zeros
max_levels <- max(length(levels_orig), length(levels_fast))
levels_orig <- c(levels_orig, rep(0, max_levels - length(levels_orig)))
levels_fast <- c(levels_fast, rep(0, max_levels - length(levels_fast)))

comparison_df <- data.frame(
  Level = 1:max_levels,
  Original = levels_orig,
  Fast = levels_fast,
  Difference = levels_orig - levels_fast
)
cat("\nSegmentation comparison across levels:\n")
print(comparison_df)

# Calculate segmentation statistics
cat("\nSegmentation quality metrics:\n")
for(level in 2:min(3, length(seg_original$segment.list))) {
  orig_sizes <- sapply(seg_original$segment.list[[level]], length)
  fast_sizes <- sapply(seg_fast$segment.list[[level]], length)
  
  cat("Level", level, ":\n")
  cat("  Original - Avg size:", round(mean(orig_sizes), 1), 
      ", Max size:", max(orig_sizes), "\n")
  cat("  Fast - Avg size:", round(mean(fast_sizes), 1), 
      ", Max size:", max(fast_sizes), "\n")
}
```

## Parameter Tuning for moneca_fast()

The `moneca_fast()` function provides several parameters for performance tuning:

### min.density Parameter

Controls early stopping based on network density:

```{r density-tuning}
# Test different density thresholds with 30-class system
data_test <- generate_mobility_data(
  n_classes = 30, 
  n_total = 25000,
  class_names = paste("Class", sprintf("%02d", 1:30)),
  seed = 456
)

cat("Testing density thresholds with 30-class system:\n")
cat("Matrix dimensions:", dim(data_test), "\n")
cat("Population:", data_test[31, 31], "\n\n")

# Conservative (lower threshold - more processing)
cat("Running conservative analysis (min.density = 0.001)...\n")
result_conservative <- moneca_fast(
  data_test, 
  min.density = 0.001, 
  max.clique.size = 8,
  progress = FALSE
)

# Aggressive (higher threshold - less processing)  
cat("Running aggressive analysis (min.density = 0.05)...\n")
result_aggressive <- moneca_fast(
  data_test, 
  min.density = 0.05, 
  max.clique.size = 8,
  progress = FALSE
)

# Standard threshold for comparison
cat("Running standard analysis (min.density = 0.01)...\n")
result_standard <- moneca_fast(
  data_test, 
  min.density = 0.01, 
  max.clique.size = 8,
  progress = FALSE
)

cat("\nDensity threshold comparison:\n")
cat("Conservative (0.001) - levels:", length(result_conservative$segment.list), 
    ", L2 segments:", length(result_conservative$segment.list[[2]]), "\n")
cat("Standard (0.01) - levels:", length(result_standard$segment.list), 
    ", L2 segments:", length(result_standard$segment.list[[2]]), "\n")
cat("Aggressive (0.05) - levels:", length(result_aggressive$segment.list), 
    ", L2 segments:", length(result_aggressive$segment.list[[2]]), "\n")

# Show effect on segmentation quality
if(length(result_conservative$segment.list) >= 2) {
  cons_sizes <- sapply(result_conservative$segment.list[[2]], length)
  std_sizes <- sapply(result_standard$segment.list[[2]], length)
  agg_sizes <- sapply(result_aggressive$segment.list[[2]], length)
  
  cat("\nLevel 2 segmentation characteristics:\n")
  cat("Conservative - Avg segment size:", round(mean(cons_sizes), 1), "\n")
  cat("Standard - Avg segment size:", round(mean(std_sizes), 1), "\n")
  cat("Aggressive - Avg segment size:", round(mean(agg_sizes), 1), "\n")
}
```

### max.clique.size Parameter

Limits maximum clique size to control computation:

```{r clique-size-tuning}
# Test different clique size limits with 30-class system
cat("Testing clique size limits with 30-class system:\n")

# Unlimited clique size (computationally intensive for 30 nodes)
cat("Running with unlimited clique size...\n")
time_unlimited <- system.time({
  result_unlimited <- moneca_fast(data_test, max.clique.size = NULL, progress = FALSE)
})

# Moderately limited clique size
cat("Running with clique size limit = 6...\n")
time_moderate <- system.time({
  result_moderate <- moneca_fast(data_test, max.clique.size = 6, progress = FALSE)
})

# Strictly limited clique size
cat("Running with clique size limit = 4...\n")
time_strict <- system.time({
  result_strict <- moneca_fast(data_test, max.clique.size = 4, progress = FALSE)
})

cat("\nClique size limit comparison:\n")
cat("Unlimited cliques:", 
    "- Time:", round(time_unlimited["elapsed"], 2), "sec",
    "- L2 segments:", length(result_unlimited$segment.list[[2]]), "\n")
cat("Moderate limit (6):", 
    "- Time:", round(time_moderate["elapsed"], 2), "sec",
    "- L2 segments:", length(result_moderate$segment.list[[2]]), "\n")
cat("Strict limit (4):", 
    "- Time:", round(time_strict["elapsed"], 2), "sec",
    "- L2 segments:", length(result_strict$segment.list[[2]]), "\n")

# Compare segmentation quality
if(length(result_unlimited$segment.list) >= 2) {
  unl_sizes <- sapply(result_unlimited$segment.list[[2]], length)
  mod_sizes <- sapply(result_moderate$segment.list[[2]], length)
  str_sizes <- sapply(result_strict$segment.list[[2]], length)
  
  cat("\nSegmentation quality comparison:\n")
  cat("Unlimited - Avg segment size:", round(mean(unl_sizes), 1), 
      ", Largest segment:", max(unl_sizes), "\n")
  cat("Moderate - Avg segment size:", round(mean(mod_sizes), 1), 
      ", Largest segment:", max(mod_sizes), "\n")
  cat("Strict - Avg segment size:", round(mean(str_sizes), 1), 
      ", Largest segment:", max(str_sizes), "\n")
  
  cat("\nRecommendation: For 30-class systems, clique size limit of 6-8 provides\n")
  cat("good balance between computational efficiency and segmentation quality.\n")
}
```

### Sparse Matrix Support

For large, sparse matrices:

```{r sparse-support}
# Test sparse matrix support with 30-class system
# Sparse matrices are particularly beneficial for large, sparse datasets

cat("Testing sparse matrix support with 30-class system:\n")

# Calculate sparsity of our test data
test_core <- data_test[1:30, 1:30]
sparsity <- sum(test_core == 0) / (30^2) * 100
cat("Data sparsity:", round(sparsity, 1), "%\n\n")

# Regular matrix processing
cat("Running with dense matrix representation...\n")
time_dense <- system.time({
  result_dense <- moneca_fast(data_test, use.sparse = FALSE, progress = FALSE)
})

# Sparse matrix processing (if Matrix package available)
if (requireNamespace("Matrix", quietly = TRUE)) {
  cat("Running with sparse matrix representation...\n")
  time_sparse <- system.time({
    result_sparse <- moneca_fast(data_test, use.sparse = TRUE, progress = FALSE)
  })
  
  cat("\nMatrix representation comparison:\n")
  cat("Dense matrices - Time:", round(time_dense["elapsed"], 2), "sec",
      "- L2 segments:", length(result_dense$segment.list[[2]]), "\n")
  cat("Sparse matrices - Time:", round(time_sparse["elapsed"], 2), "sec",
      "- L2 segments:", length(result_sparse$segment.list[[2]]), "\n")
  
  # Compare memory usage
  cat("\nApproximate memory usage:\n")
  cat("Dense result:", round(object.size(result_dense) / 1024^2, 2), "MB\n")
  cat("Sparse result:", round(object.size(result_sparse) / 1024^2, 2), "MB\n")
  
  # Check if results are identical
  identical_sparse <- identical(result_dense$segment.list, result_sparse$segment.list)
  cat("Results identical:", identical_sparse, "\n")
  
  cat("\nNote: Sparse matrices are most beneficial when data sparsity > 70%\n")
  cat("Current data sparsity:", round(sparsity, 1), "% - ", 
      if(sparsity > 70) "Good candidate for sparse representation" else "Dense representation may be sufficient", "\n")
  
} else {
  cat("Matrix package not available - sparse support skipped\n")
  cat("Install Matrix package with: install.packages('Matrix')\n")
}
```

## Decision Guidelines

### When to Use moneca()

Choose the original `moneca()` function when:

1. **Accuracy is paramount**: You need the most comprehensive and conservative segmentation
2. **Small to medium datasets**: Network size is manageable (< 15 nodes typically)
3. **Reproducibility is critical**: You need identical results across different runs and platforms
4. **Methodological consistency**: You're replicating or extending previous research using MONECA
5. **Edge case handling**: You're working with unusual network structures that might challenge optimizations

### When to Use moneca_fast()

Choose the optimized `moneca_fast()` function when:

1. **Performance is important**: You're working with larger networks or need faster results
2. **Exploratory analysis**: You're doing initial exploration and can accept minor differences in segmentation
3. **Production environments**: You need reliable performance characteristics for automated analyses  
4. **Resource constraints**: You have limited computational resources or memory
5. **Large-scale studies**: You're processing multiple datasets and need efficiency

### Hybrid Approach

For comprehensive analysis, consider using both:

```{r hybrid-approach}
# Demonstrate hybrid approach with 30-class system
hybrid_data <- generate_mobility_data(
  n_classes = 30,
  n_total = 40000,
  class_names = paste("Class", sprintf("%02d", 1:30)),
  seed = 999
)

cat("Hybrid approach with 30-class system:\n")
cat("Step 1: Fast exploration...\n")

# Start with fast version for exploration
time_initial <- system.time({
  initial_result <- moneca_fast(
    hybrid_data, 
    segment.levels = 3, 
    max.clique.size = 6,
    progress = FALSE
  )
})

cat("Fast exploration completed in", round(time_initial["elapsed"], 2), "seconds\n")
cat("Levels found:", length(initial_result$segment.list), "\n")
cat("Level 2 segments:", length(initial_result$segment.list[[2]]), "\n")

# If results look promising and accuracy is needed, validate with original
if (length(initial_result$segment.list) > 2) {
  cat("\nStep 2: Detailed validation with original algorithm...\n")
  time_validation <- system.time({
    final_result <- moneca(hybrid_data, segment.levels = 3)
  })
  
  cat("Validation completed in", round(time_validation["elapsed"], 2), "seconds\n")
  cat("\nComparison of hybrid approach results:\n")
  cat("Fast (exploration) - L2 segments:", length(initial_result$segment.list[[2]]), "\n")
  cat("Original (validation) - L2 segments:", length(final_result$segment.list[[2]]), "\n")
  
  # Check agreement
  results_match <- identical(initial_result$segment.list, final_result$segment.list)
  cat("Results match:", results_match, "\n")
  
  if(!results_match) {
    cat("\nDifferences found - Original algorithm provides more conservative segmentation\n")
    cat("Total time for hybrid approach:", 
        round(time_initial["elapsed"] + time_validation["elapsed"], 2), "seconds\n")
  } else {
    cat("\nResults identical - Fast algorithm was sufficient\n")
    cat("Time saved by using fast algorithm:", 
        round(time_validation["elapsed"] - time_initial["elapsed"], 2), "seconds\n")
  }
  
  cat("\nHybrid approach: Fast exploration followed by selective validation\n")
  cat("Recommended for: Large datasets where accuracy is critical but\n")
  cat("computational efficiency is also important.\n")
}
```

## Quality Assessment

Both algorithms should produce similar high-level segmentation patterns, but may differ in details:

### Comparing Algorithm Outputs

```{r quality-assessment}
# Enhanced function to compare segmentation quality for 30-class systems
compare_segmentations <- function(seg1, seg2, level = 2, data_matrix = NULL) {
  if (length(seg1$segment.list) < level || length(seg2$segment.list) < level) {
    return("Insufficient levels for comparison")
  }
  
  # Compare number of segments
  n_segments_1 <- length(seg1$segment.list[[level]])
  n_segments_2 <- length(seg2$segment.list[[level]])
  
  # Calculate segment size distributions
  sizes_1 <- sapply(seg1$segment.list[[level]], length)
  sizes_2 <- sapply(seg2$segment.list[[level]], length)
  
  # Calculate additional quality metrics
  results <- list(
    n_segments = c(algorithm1 = n_segments_1, algorithm2 = n_segments_2),
    avg_segment_size = c(algorithm1 = round(mean(sizes_1), 1), algorithm2 = round(mean(sizes_2), 1)),
    size_variance = c(algorithm1 = round(var(sizes_1), 1), algorithm2 = round(var(sizes_2), 1)),
    max_segment_size = c(algorithm1 = max(sizes_1), algorithm2 = max(sizes_2)),
    min_segment_size = c(algorithm1 = min(sizes_1), algorithm2 = min(sizes_2)),
    size_distribution_1 = sizes_1,
    size_distribution_2 = sizes_2
  )
  
  # If data matrix provided, calculate internal mobility
  if(!is.null(data_matrix)) {
    # Calculate internal mobility for each algorithm at specified level
    mx1 <- seg1$mat.list[[level]]
    mx2 <- seg2$mat.list[[level]]
    
    l1 <- ncol(mx1)
    l2 <- ncol(mx2)
    
    internal1 <- sum(diag(mx1[1:(l1-1), 1:(l1-1)])) / sum(mx1[1:(l1-1), 1:(l1-1)]) * 100
    internal2 <- sum(diag(mx2[1:(l2-1), 1:(l2-1)])) / sum(mx2[1:(l2-1), 1:(l2-1)]) * 100
    
    results$internal_mobility <- c(algorithm1 = round(internal1, 1), algorithm2 = round(internal2, 1))
  }
  
  return(results)
}

# Compare algorithms using our 30-class example data
if(exists("result_orig") && exists("result_fast")) {
  cat("Comprehensive quality assessment for 30-class system:\n\n")
  comparison <- compare_segmentations(result_orig, result_fast, level = 2, large_data)
  
  cat("Number of segments:\n")
  cat("  Original algorithm:", comparison$n_segments["algorithm1"], "\n")
  cat("  Fast algorithm:", comparison$n_segments["algorithm2"], "\n")
  
  cat("\nAverage segment size:\n")
  cat("  Original algorithm:", comparison$avg_segment_size["algorithm1"], "classes\n")
  cat("  Fast algorithm:", comparison$avg_segment_size["algorithm2"], "classes\n")
  
  cat("\nSegment size range:\n")
  cat("  Original algorithm:", comparison$min_segment_size["algorithm1"], "-", 
      comparison$max_segment_size["algorithm1"], "classes\n")
  cat("  Fast algorithm:", comparison$min_segment_size["algorithm2"], "-", 
      comparison$max_segment_size["algorithm2"], "classes\n")
  
  if(!is.null(comparison$internal_mobility)) {
    cat("\nInternal mobility (Level 2):\n")
    cat("  Original algorithm:", comparison$internal_mobility["algorithm1"], "%\n")
    cat("  Fast algorithm:", comparison$internal_mobility["algorithm2"], "%\n")
  }
  
  cat("\nSegment size distributions:\n")
  cat("  Original:", paste(sort(comparison$size_distribution_1, decreasing = TRUE), collapse = ", "), "\n")
  cat("  Fast:", paste(sort(comparison$size_distribution_2, decreasing = TRUE), collapse = ", "), "\n")
  
  # Statistical comparison
  cat("\nStatistical comparison:\n")
  cat("  Size variance (lower = more balanced segmentation):\n")
  cat("    Original:", comparison$size_variance["algorithm1"], "\n")
  cat("    Fast:", comparison$size_variance["algorithm2"], "\n")
  
  # Overall assessment
  cat("\nOverall assessment:\n")
  if(abs(comparison$n_segments["algorithm1"] - comparison$n_segments["algorithm2"]) <= 1) {
    cat("  Segment counts very similar - both algorithms effective\n")
  } else {
    cat("  Notable difference in segment counts - investigate further\n")
  }
  
  if(!is.null(comparison$internal_mobility)) {
    mobility_diff <- abs(comparison$internal_mobility["algorithm1"] - comparison$internal_mobility["algorithm2"])
    if(mobility_diff < 5) {
      cat("  Internal mobility rates very similar - consistent quality\n")
    } else {
      cat("  Notable difference in internal mobility - algorithms may emphasize different patterns\n")
    }
  }
} else {
  cat("Previous algorithm results not available for comparison\n")
  cat("Run the performance comparison section first\n")
}
```

### Validation Strategies

1. **Cross-validation**: Run both algorithms and compare results
2. **Sensitivity analysis**: Test with different parameters
3. **Visualization**: Plot results to assess segmentation quality
4. **Domain expertise**: Validate results against substantive knowledge

```{r validation-example}
# Visualize results from both algorithms
if (requireNamespace("ggraph", quietly = TRUE)) {
  # Note: In practice, you would create actual plots here
  cat("Both algorithms can be visualized using plot_moneca_ggraph()\n")
  cat("Compare visual output for validation\n")
}
```

## Conclusion

Both `moneca()` and `moneca_fast()` implement the core MONECA methodology effectively, but with different optimization strategies:

### Summary of Key Differences

| Aspect | moneca() | moneca_fast() |
|--------|----------|---------------|
| **Clique Strategy** | All cliques | Maximal cliques |
| **Performance** | Slower, thorough | Faster, optimized |
| **Memory Usage** | Higher | Lower |
| **Accuracy** | Maximally conservative | Practically accurate |
| **Parameter Complexity** | Simple | More options |
| **Best Use Case** | Small networks, maximum accuracy | Larger networks, good performance |

### Recommendations

1. **Start with moneca_fast()** for initial exploration and most practical applications
2. **Use moneca()** when accuracy is critical or networks are small
3. **Compare results** when in doubt about which algorithm to trust
4. **Consider dataset characteristics** - sparse vs. dense, small vs. large
5. **Validate results** using domain knowledge and visualization

The choice between algorithms should be based on your specific requirements for accuracy, performance, and the characteristics of your mobility data. Both algorithms are valid implementations of the MONECA methodology and will provide valuable insights into mobility patterns and social structure.

## References

- Toubøl, J., & Larsen, A. G. (2017). Mapping the Social Class Structure: From Occupational Mobility to Social Class Categories Using Network Analysis. *Sociology*, 51(6), 1257-1276.

## Session Information

```{r session-info}
sessionInfo()
```